{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1b5b9a",
   "metadata": {},
   "source": [
    "# XML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57da3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>lastmod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/news-site...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/standalon...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/overall-m...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/overall-s...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/story.xml.gz</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/overall-c...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/overall-c...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/overall-c...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/format-re...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/overall-t...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/overall-v...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-d...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-h...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-y...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-y...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-t...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-t...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-t...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-t...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>https://www.espncricinfo.com/sitemap/records-t...</td>\n",
       "      <td>2023-11-21T01:01:02+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  loc  \\\n",
       "0   https://www.espncricinfo.com/sitemap/news-site...   \n",
       "1   https://www.espncricinfo.com/sitemap/standalon...   \n",
       "2   https://www.espncricinfo.com/sitemap/overall-m...   \n",
       "3   https://www.espncricinfo.com/sitemap/overall-s...   \n",
       "4   https://www.espncricinfo.com/sitemap/story.xml.gz   \n",
       "5   https://www.espncricinfo.com/sitemap/overall-c...   \n",
       "6   https://www.espncricinfo.com/sitemap/overall-c...   \n",
       "7   https://www.espncricinfo.com/sitemap/overall-c...   \n",
       "8   https://www.espncricinfo.com/sitemap/format-re...   \n",
       "9   https://www.espncricinfo.com/sitemap/overall-t...   \n",
       "10  https://www.espncricinfo.com/sitemap/overall-v...   \n",
       "11  https://www.espncricinfo.com/sitemap/records-d...   \n",
       "12  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "13  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "14  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "15  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "16  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "17  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "18  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "19  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "20  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "21  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "22  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "23  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "24  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "25  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "26  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "27  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "28  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "29  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "30  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "31  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "32  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "33  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "34  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "35  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "36  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "37  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "38  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "39  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "40  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "41  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "42  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "43  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "44  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "45  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "46  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "47  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "48  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "49  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "50  https://www.espncricinfo.com/sitemap/records-h...   \n",
       "51  https://www.espncricinfo.com/sitemap/records-y...   \n",
       "52  https://www.espncricinfo.com/sitemap/records-y...   \n",
       "53  https://www.espncricinfo.com/sitemap/records-t...   \n",
       "54  https://www.espncricinfo.com/sitemap/records-t...   \n",
       "55  https://www.espncricinfo.com/sitemap/records-t...   \n",
       "56  https://www.espncricinfo.com/sitemap/records-t...   \n",
       "57  https://www.espncricinfo.com/sitemap/records-t...   \n",
       "\n",
       "                      lastmod  \n",
       "0   2023-11-21T01:01:02+00:00  \n",
       "1   2023-11-21T01:01:02+00:00  \n",
       "2   2023-11-21T01:01:02+00:00  \n",
       "3   2023-11-21T01:01:02+00:00  \n",
       "4   2023-11-21T01:01:02+00:00  \n",
       "5   2023-11-21T01:01:02+00:00  \n",
       "6   2023-11-21T01:01:02+00:00  \n",
       "7   2023-11-21T01:01:02+00:00  \n",
       "8   2023-11-21T01:01:02+00:00  \n",
       "9   2023-11-21T01:01:02+00:00  \n",
       "10  2023-11-21T01:01:02+00:00  \n",
       "11  2023-11-21T01:01:02+00:00  \n",
       "12  2023-11-21T01:01:02+00:00  \n",
       "13  2023-11-21T01:01:02+00:00  \n",
       "14  2023-11-21T01:01:02+00:00  \n",
       "15  2023-11-21T01:01:02+00:00  \n",
       "16  2023-11-21T01:01:02+00:00  \n",
       "17  2023-11-21T01:01:02+00:00  \n",
       "18  2023-11-21T01:01:02+00:00  \n",
       "19  2023-11-21T01:01:02+00:00  \n",
       "20  2023-11-21T01:01:02+00:00  \n",
       "21  2023-11-21T01:01:02+00:00  \n",
       "22  2023-11-21T01:01:02+00:00  \n",
       "23  2023-11-21T01:01:02+00:00  \n",
       "24  2023-11-21T01:01:02+00:00  \n",
       "25  2023-11-21T01:01:02+00:00  \n",
       "26  2023-11-21T01:01:02+00:00  \n",
       "27  2023-11-21T01:01:02+00:00  \n",
       "28  2023-11-21T01:01:02+00:00  \n",
       "29  2023-11-21T01:01:02+00:00  \n",
       "30  2023-11-21T01:01:02+00:00  \n",
       "31  2023-11-21T01:01:02+00:00  \n",
       "32  2023-11-21T01:01:02+00:00  \n",
       "33  2023-11-21T01:01:02+00:00  \n",
       "34  2023-11-21T01:01:02+00:00  \n",
       "35  2023-11-21T01:01:02+00:00  \n",
       "36  2023-11-21T01:01:02+00:00  \n",
       "37  2023-11-21T01:01:02+00:00  \n",
       "38  2023-11-21T01:01:02+00:00  \n",
       "39  2023-11-21T01:01:02+00:00  \n",
       "40  2023-11-21T01:01:02+00:00  \n",
       "41  2023-11-21T01:01:02+00:00  \n",
       "42  2023-11-21T01:01:02+00:00  \n",
       "43  2023-11-21T01:01:02+00:00  \n",
       "44  2023-11-21T01:01:02+00:00  \n",
       "45  2023-11-21T01:01:02+00:00  \n",
       "46  2023-11-21T01:01:02+00:00  \n",
       "47  2023-11-21T01:01:02+00:00  \n",
       "48  2023-11-21T01:01:02+00:00  \n",
       "49  2023-11-21T01:01:02+00:00  \n",
       "50  2023-11-21T01:01:02+00:00  \n",
       "51  2023-11-21T01:01:02+00:00  \n",
       "52  2023-11-21T01:01:02+00:00  \n",
       "53  2023-11-21T01:01:02+00:00  \n",
       "54  2023-11-21T01:01:02+00:00  \n",
       "55  2023-11-21T01:01:02+00:00  \n",
       "56  2023-11-21T01:01:02+00:00  \n",
       "57  2023-11-21T01:01:02+00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the XMLDataFetcher class from the custom module\n",
    "# The module is located in the src/Web_Scraping_Python/Web_Scraping_XML directory\n",
    "import src.Web_Scraping_Python.Web_Scraping_XML as xml\n",
    "\n",
    "# Define the URL from which the XML data will be fetched\n",
    "# In this case, the data is being fetched from the ESPN Cricinfo sitemap\n",
    "url = 'https://www.espncricinfo.com/sitemap.xml'\n",
    "\n",
    "# Create an instance of the XMLDataFetcher class\n",
    "# The class is responsible for fetching and parsing the XML data from the given URL\n",
    "fetcher = xml.XMLDataFetcher(url)\n",
    "\n",
    "# Use the get_data method of the XMLDataFetcher instance\n",
    "# This method fetches the XML data from the URL and parses it into a pandas DataFrame\n",
    "df = fetcher.get_data()\n",
    "\n",
    "# Print the DataFrame to view the fetched and parsed data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb79ad6",
   "metadata": {},
   "source": [
    "The dataset obtained from the provided code comes from parsing the XML sitemap of the ESPN Cricinfo website. XML sitemaps are used by webmasters to inform search engines about pages on their websites that are available for crawling. In this case, the dataset likely contains URLs and possibly the last modified dates of various pages or articles on the ESPN Cricinfo website.\n",
    "\n",
    "### Description of the Dataset:\n",
    "\n",
    "After executing the provided code, the resulting dataset (`df`), a pandas DataFrame, is expected to have the following structure:\n",
    "\n",
    "- **Columns**: Typically, two columns based on the parsing logic in `parse_xml_to_dataframe` method.\n",
    "  - `loc`: Contains URLs found in the sitemap. Each URL represents a specific page on the ESPN Cricinfo website.\n",
    "  - `lastmod`: The last modified date of each URL, indicating when the content at that URL was last updated.\n",
    "\n",
    "### Potential Uses of the Dataset:\n",
    "\n",
    "1. **SEO and Web Analytics**: The dataset can be used for Search Engine Optimization (SEO) purposes. By analyzing the sitemap URLs, one can understand the structure of the website, identify all available pages, and ensure that search engines are effectively crawling and indexing the site.\n",
    "\n",
    "2. **Content Change Tracking**: By monitoring the `lastmod` dates, it’s possible to track when content on the website is updated. This can be particularly useful for websites that frequently update their content, like news or sports websites.\n",
    "\n",
    "3. **Building a Web Crawler**: If you're building a web crawler or scraper (for legal and ethical purposes), the sitemap provides a comprehensive list of URLs to start with. It can guide your crawler to relevant pages, ensuring a more efficient and complete crawling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211a881",
   "metadata": {},
   "source": [
    "# Using an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0686ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Released</th>\n",
       "      <th>Episode</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>imdbID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winter Is Coming</td>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>tt1480055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Kingsroad</td>\n",
       "      <td>2011-04-24</td>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>tt1668746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lord Snow</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>tt1829962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cripples, Bastards, and Broken Things</td>\n",
       "      <td>2011-05-08</td>\n",
       "      <td>4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>tt1829963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Wolf and the Lion</td>\n",
       "      <td>2011-05-15</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>tt1829964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Golden Crown</td>\n",
       "      <td>2011-05-22</td>\n",
       "      <td>6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>tt1837862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You Win or You Die</td>\n",
       "      <td>2011-05-29</td>\n",
       "      <td>7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>tt1837863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Pointy End</td>\n",
       "      <td>2011-06-05</td>\n",
       "      <td>8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>tt1837864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baelor</td>\n",
       "      <td>2011-06-12</td>\n",
       "      <td>9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>tt1851398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fire and Blood</td>\n",
       "      <td>2011-06-19</td>\n",
       "      <td>10</td>\n",
       "      <td>N/A</td>\n",
       "      <td>tt1851397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title    Released Episode imdbRating  \\\n",
       "0                       Winter Is Coming  2011-04-17       1        8.9   \n",
       "1                          The Kingsroad  2011-04-24       2        8.6   \n",
       "2                              Lord Snow  2011-05-01       3        8.5   \n",
       "3  Cripples, Bastards, and Broken Things  2011-05-08       4        8.6   \n",
       "4                  The Wolf and the Lion  2011-05-15       5        9.0   \n",
       "5                         A Golden Crown  2011-05-22       6        9.1   \n",
       "6                     You Win or You Die  2011-05-29       7        9.1   \n",
       "7                         The Pointy End  2011-06-05       8        8.9   \n",
       "8                                 Baelor  2011-06-12       9        9.6   \n",
       "9                         Fire and Blood  2011-06-19      10        N/A   \n",
       "\n",
       "      imdbID  \n",
       "0  tt1480055  \n",
       "1  tt1668746  \n",
       "2  tt1829962  \n",
       "3  tt1829963  \n",
       "4  tt1829964  \n",
       "5  tt1837862  \n",
       "6  tt1837863  \n",
       "7  tt1837864  \n",
       "8  tt1851398  \n",
       "9  tt1851397  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the fetch_tv_season_data class from the custom module\n",
    "# The module is located in the src/Web_Scraping_Python/Web_Scraping_XML directory\n",
    "import src.Web_Scraping_Python.Web_Scraping_API as api\n",
    "\n",
    "# Define the API key for OMDb API access\n",
    "# You can obtain an API key by registering on the OMDb website.\n",
    "api_key = \"cc3345b3\"\n",
    "\n",
    "# Call the fetch_tv_season_data function to fetch data for a specific TV show and season\n",
    "# Here, we're fetching data for Season 1 of \"Game of Thrones\".\n",
    "# The function takes three parameters: the TV show title, the season number, and the API key.\n",
    "season_df = api.fetch_tv_season_data(\"Game of Thrones\", 1, api_key)\n",
    "\n",
    "# Print the resulting DataFrame to the console\n",
    "# The DataFrame contains information about each episode in the specified season,\n",
    "# including episode number, title, released date, and other details provided by the OMDb API.\n",
    "season_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153da8e",
   "metadata": {},
   "source": [
    "The code provided defines a Python function, `fetch_tv_season_data`, that fetches data for a specific season of a TV show from the OMDb API (Open Movie Database) and converts this data into a pandas DataFrame. The example usage of this function retrieves data for Season 1 of \"Game of Thrones.\"\n",
    "\n",
    "### Description of the Dataset:\n",
    "\n",
    "After executing the code, the resulting dataset, stored in `season_df`, is a pandas DataFrame with the following characteristics:\n",
    "\n",
    "1. **Columns**: The DataFrame typically includes several columns corresponding to the details of each episode in the specified TV show season. These details often include:\n",
    "   - Episode title\n",
    "   - Release date\n",
    "   - Episode number (within the season)\n",
    "   - IMDb rating\n",
    "   - IMDb ID\n",
    "\n",
    "2. **Rows**: Each row in the DataFrame represents an individual episode of the specified season of the TV show.\n",
    "\n",
    "### Potential Uses of the Dataset:\n",
    "\n",
    "1. **Data Analysis**: Perform statistical analysis on various aspects of the TV show, such as rating trends across episodes, release patterns.\n",
    "\n",
    "2. **Recommendation Systems**: Use the data as part of a content recommendation system, where insights from the show’s episodes could contribute to recommending similar TV shows or episodes to users.\n",
    "\n",
    "3. **Content Curation and Review Platforms**: If you are developing a platform for TV show reviews or content curation, this data can be valuable for creating episode guides, summaries, and providing additional context to users.\n",
    "\n",
    "4. **Educational Purposes**: In a media studies context, the dataset could be used for analysis and discussion about TV show structure, narrative development, and audience reception (reflected in ratings).\n",
    "\n",
    "5. **Fan Websites and Apps**: If you are developing an application or website for fans of the TV show, this dataset can provide structured information for episode guides, trivia games, or fan discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bacc65",
   "metadata": {},
   "source": [
    "# Web Scraping - Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07240975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Country,Other</th>\n",
       "      <th>TotalCases</th>\n",
       "      <th>NewCases</th>\n",
       "      <th>TotalDeaths</th>\n",
       "      <th>NewDeaths</th>\n",
       "      <th>TotalRecovered</th>\n",
       "      <th>NewRecovered</th>\n",
       "      <th>ActiveCases</th>\n",
       "      <th>Serious,Critical</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalTests</th>\n",
       "      <th>Tests/\\n1M pop</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>1 Caseevery X ppl</th>\n",
       "      <th>1 Deathevery X ppl</th>\n",
       "      <th>1 Testevery X ppl</th>\n",
       "      <th>New Cases/1M pop</th>\n",
       "      <th>New Deaths/1M pop</th>\n",
       "      <th>Active Cases/1M pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>North America</td>\n",
       "      <td>129,221,735</td>\n",
       "      <td></td>\n",
       "      <td>1,654,597</td>\n",
       "      <td></td>\n",
       "      <td>124,981,104</td>\n",
       "      <td>+1,136</td>\n",
       "      <td>2,586,034</td>\n",
       "      <td>6,394</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>North America</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Asia</td>\n",
       "      <td>220,874,423</td>\n",
       "      <td></td>\n",
       "      <td>1,551,778</td>\n",
       "      <td></td>\n",
       "      <td>204,540,022</td>\n",
       "      <td></td>\n",
       "      <td>14,782,623</td>\n",
       "      <td>14,727</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Asia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Europe</td>\n",
       "      <td>251,122,770</td>\n",
       "      <td></td>\n",
       "      <td>2,081,565</td>\n",
       "      <td></td>\n",
       "      <td>246,862,347</td>\n",
       "      <td>+1,646</td>\n",
       "      <td>2,178,858</td>\n",
       "      <td>4,586</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Europe</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>South America</td>\n",
       "      <td>69,262,022</td>\n",
       "      <td></td>\n",
       "      <td>1,362,792</td>\n",
       "      <td></td>\n",
       "      <td>66,565,231</td>\n",
       "      <td></td>\n",
       "      <td>1,333,999</td>\n",
       "      <td>8,972</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>South America</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Oceania</td>\n",
       "      <td>14,613,562</td>\n",
       "      <td>+1,574</td>\n",
       "      <td>30,867</td>\n",
       "      <td></td>\n",
       "      <td>14,464,481</td>\n",
       "      <td></td>\n",
       "      <td>118,214</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Australia/Oceania</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>88</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>552,695</td>\n",
       "      <td></td>\n",
       "      <td>5,856</td>\n",
       "      <td></td>\n",
       "      <td>546,537</td>\n",
       "      <td></td>\n",
       "      <td>302</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>3,359,014</td>\n",
       "      <td>114,771</td>\n",
       "      <td>29,266,991</td>\n",
       "      <td>South America</td>\n",
       "      <td>53</td>\n",
       "      <td>4,998</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>89</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>516,023</td>\n",
       "      <td></td>\n",
       "      <td>24,613</td>\n",
       "      <td></td>\n",
       "      <td>442,182</td>\n",
       "      <td></td>\n",
       "      <td>49,228</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>3,693,367</td>\n",
       "      <td>34,792</td>\n",
       "      <td>106,156,692</td>\n",
       "      <td>Africa</td>\n",
       "      <td>206</td>\n",
       "      <td>4,313</td>\n",
       "      <td>29</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>90</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>514,524</td>\n",
       "      <td></td>\n",
       "      <td>690</td>\n",
       "      <td></td>\n",
       "      <td>513,687</td>\n",
       "      <td></td>\n",
       "      <td>147</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>4,065,369</td>\n",
       "      <td>1,364,257</td>\n",
       "      <td>2,979,915</td>\n",
       "      <td>Asia</td>\n",
       "      <td>6</td>\n",
       "      <td>4,319</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>91</td>\n",
       "      <td>Libya</td>\n",
       "      <td>507,274</td>\n",
       "      <td></td>\n",
       "      <td>6,437</td>\n",
       "      <td></td>\n",
       "      <td>500,835</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2,483,848</td>\n",
       "      <td>352,782</td>\n",
       "      <td>7,040,745</td>\n",
       "      <td>Africa</td>\n",
       "      <td>14</td>\n",
       "      <td>1,094</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>92</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>501,060</td>\n",
       "      <td></td>\n",
       "      <td>7,574</td>\n",
       "      <td></td>\n",
       "      <td>488,171</td>\n",
       "      <td></td>\n",
       "      <td>5,315</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>5,565,340</td>\n",
       "      <td>46,066</td>\n",
       "      <td>120,812,698</td>\n",
       "      <td>Africa</td>\n",
       "      <td>241</td>\n",
       "      <td>15,951</td>\n",
       "      <td>22</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #  Country,Other   TotalCases NewCases TotalDeaths NewDeaths  \\\n",
       "0       North America  129,221,735            1,654,597             \n",
       "1                Asia  220,874,423            1,551,778             \n",
       "2              Europe  251,122,770            2,081,565             \n",
       "3       South America   69,262,022            1,362,792             \n",
       "4             Oceania   14,613,562   +1,574      30,867             \n",
       "..  ..            ...          ...      ...         ...       ...   \n",
       "95  88      Venezuela      552,695                5,856             \n",
       "96  89          Egypt      516,023               24,613             \n",
       "97  90          Qatar      514,524                  690             \n",
       "98  91          Libya      507,274                6,437             \n",
       "99  92       Ethiopia      501,060                7,574             \n",
       "\n",
       "   TotalRecovered NewRecovered ActiveCases Serious,Critical  ... TotalTests  \\\n",
       "0     124,981,104       +1,136   2,586,034            6,394  ...              \n",
       "1     204,540,022               14,782,623           14,727  ...              \n",
       "2     246,862,347       +1,646   2,178,858            4,586  ...              \n",
       "3      66,565,231                1,333,999            8,972  ...              \n",
       "4      14,464,481                  118,214               49  ...              \n",
       "..            ...          ...         ...              ...  ...        ...   \n",
       "95        546,537                      302               31  ...  3,359,014   \n",
       "96        442,182                   49,228              122  ...  3,693,367   \n",
       "97        513,687                      147               16  ...  4,065,369   \n",
       "98        500,835                        2                   ...  2,483,848   \n",
       "99        488,171                    5,315                   ...  5,565,340   \n",
       "\n",
       "   Tests/\\n1M pop   Population          Continent 1 Caseevery X ppl  \\\n",
       "0                                   North America                     \n",
       "1                                            Asia                     \n",
       "2                                          Europe                     \n",
       "3                                   South America                     \n",
       "4                               Australia/Oceania                     \n",
       "..            ...          ...                ...               ...   \n",
       "95        114,771   29,266,991      South America                53   \n",
       "96         34,792  106,156,692             Africa               206   \n",
       "97      1,364,257    2,979,915               Asia                 6   \n",
       "98        352,782    7,040,745             Africa                14   \n",
       "99         46,066  120,812,698             Africa               241   \n",
       "\n",
       "   1 Deathevery X ppl 1 Testevery X ppl New Cases/1M pop New Deaths/1M pop  \\\n",
       "0                                                                            \n",
       "1                                                                            \n",
       "2                                                                            \n",
       "3                                                                            \n",
       "4                                                                            \n",
       "..                ...               ...              ...               ...   \n",
       "95              4,998                 9                                      \n",
       "96              4,313                29                                      \n",
       "97              4,319                 1                                      \n",
       "98              1,094                 3                                      \n",
       "99             15,951                22                                      \n",
       "\n",
       "   Active Cases/1M pop  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       \n",
       "..                 ...  \n",
       "95                  10  \n",
       "96                 464  \n",
       "97                  49  \n",
       "98                 0.3  \n",
       "99                  44  \n",
       "\n",
       "[100 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the class CovidDataScraper class from the custom module\n",
    "# The module is located in the src/Web_Scraping_Python/Web_Scraping_BeautifullSoap directory\n",
    "import src.Web_Scraping_Python.Web_Scraping_BeautifulSoup as bs\n",
    "\n",
    "# Creating an instance of the CovidDataScraper class\n",
    "# This class is designed to scrape COVID-19 data from the Worldometer website.\n",
    "scraper = bs.CovidDataScraper()\n",
    "\n",
    "# Fetching the COVID-19 data using the get_data method of the scraper instance.\n",
    "# The get_data method internally fetches the HTML content from the Worldometer website\n",
    "# and parses it to extract and structure the COVID-19 data into a pandas DataFrame.\n",
    "covid_df = scraper.get_data()\n",
    "\n",
    "# Printing the first 100 rows of the DataFrame to the console.\n",
    "# This provides a preview of the COVID-19 data that has been scraped and structured.\n",
    "# The DataFrame typically contains information about COVID-19 cases, deaths, recoveries, etc.,\n",
    "# for various countries and regions, as reported on the Worldometer website.\n",
    "covid_df.head(100)  # Display the first few rows of the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d9e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to work on few EDA of Web_Scraping_BeautifullSoup on vscode like removing few rows \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86131c5",
   "metadata": {},
   "source": [
    "The provided code defines a Python class named `CovidDataScraper`, which is designed to scrape COVID-19 data from the Worldometer website and format it into a pandas DataFrame. The usage example demonstrates how to instantiate this class and use it to obtain and display COVID-19 data.\n",
    "\n",
    "### Description of the Dataset:\n",
    "\n",
    "After executing the code, the resulting dataset, stored in `covid_df`, is expected to have the following characteristics:\n",
    "\n",
    "1. **Columns**: The DataFrame typically includes several columns corresponding to the details of COVID-19 statistics reported on the Worldometer website. These might include:\n",
    "   - Country/Region\n",
    "   - Total Cases\n",
    "   - New Cases\n",
    "   - Total Deaths\n",
    "   - New Deaths\n",
    "   - Total Recovered\n",
    "   - Active Cases\n",
    "   - Serious/Critical Conditions\n",
    "   - Cases per Million\n",
    "   - Deaths per Million\n",
    "   - Total Tests\n",
    "   - Tests per Million\n",
    "   - Population\n",
    "\n",
    "\n",
    "2. **Rows**: Each row in the DataFrame represents a different country or region, along with its respective COVID-19 statistics.\n",
    "\n",
    "### Potential Uses of the Dataset:\n",
    "\n",
    "1. **Trend Analysis**: Analyze the trends of COVID-19 cases and deaths globally or within specific countries or regions.\n",
    "\n",
    "2. **Comparative Analysis**: Compare COVID-19 statistics between different countries or regions, such as infection rates, mortality rates, recovery rates, etc.\n",
    "\n",
    "3. **Data Visualization**: Create visual representations of the data, such as graphs and charts, to better understand the spread and impact of the pandemic.\n",
    "\n",
    "4. **Policy Making and Public Health Analysis**: Use the data to inform public health decisions, policy making, and resource allocation.\n",
    "\n",
    "5. **Educational Purposes**: Use the dataset for academic research or educational purposes to understand the dynamics of the pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7c012",
   "metadata": {},
   "source": [
    "# Web Scraping - Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3265e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>P</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>NR</th>\n",
       "      <th>NRR</th>\n",
       "      <th>FOR</th>\n",
       "      <th>AGAINST</th>\n",
       "      <th>PTS</th>\n",
       "      <th>RECENT FORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>GT</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.809</td>\n",
       "      <td>2450/268.1</td>\n",
       "      <td>2326/279.2</td>\n",
       "      <td>20</td>\n",
       "      <td>WWLWW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>CSK</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.652</td>\n",
       "      <td>2369/254.3</td>\n",
       "      <td>2232/257.5</td>\n",
       "      <td>17</td>\n",
       "      <td>WLWWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>LSG</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284</td>\n",
       "      <td>2253/255.2</td>\n",
       "      <td>2216/259.3</td>\n",
       "      <td>17</td>\n",
       "      <td>WWWLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>MI</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>2592/270.3</td>\n",
       "      <td>2620/272.1</td>\n",
       "      <td>16</td>\n",
       "      <td>WLWWL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>RR</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148</td>\n",
       "      <td>2419/272.1</td>\n",
       "      <td>2389/273.2</td>\n",
       "      <td>14</td>\n",
       "      <td>WLWLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>RCB</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>2502/275.4</td>\n",
       "      <td>2435/272.2</td>\n",
       "      <td>14</td>\n",
       "      <td>LWWLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>KKR</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>2463/274.3</td>\n",
       "      <td>2432/264.0</td>\n",
       "      <td>12</td>\n",
       "      <td>LWLWW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>PBKS</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>2518/275.3</td>\n",
       "      <td>2564/271.3</td>\n",
       "      <td>12</td>\n",
       "      <td>LLWLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>DC</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>2182/276.0</td>\n",
       "      <td>2424/278.1</td>\n",
       "      <td>10</td>\n",
       "      <td>LWLLW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>SRH</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>2376/277.1</td>\n",
       "      <td>2486/271.2</td>\n",
       "      <td>8</td>\n",
       "      <td>LLLLW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POS    TEAM   P   W   L NR     NRR         FOR     AGAINST PTS RECENT FORM\n",
       "0   1      GT  14  10   4  0   0.809  2450/268.1  2326/279.2  20       WWLWW\n",
       "1   2     CSK  14   8   5  1   0.652  2369/254.3  2232/257.5  17       WLWWN\n",
       "2   3     LSG  14   8   5  1   0.284  2253/255.2  2216/259.3  17       WWWLN\n",
       "3   4      MI  14   8   6  0  -0.044  2592/270.3  2620/272.1  16       WLWWL\n",
       "4   5      RR  14   7   7  0   0.148  2419/272.1  2389/273.2  14       WLWLL\n",
       "5   6     RCB  14   7   7  0   0.135  2502/275.4  2435/272.2  14       LWWLL\n",
       "6   7     KKR  14   6   8  0  -0.239  2463/274.3  2432/264.0  12       LWLWW\n",
       "7   8    PBKS  14   6   8  0  -0.304  2518/275.3  2564/271.3  12       LLWLL\n",
       "8   9      DC  14   5   9  0  -0.808  2182/276.0  2424/278.1  10       LWLLW\n",
       "9  10     SRH  14   4  10  0  -0.590  2376/277.1  2486/271.2   8       LLLLW"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the class CovidDataScraper class from the custom module\n",
    "# The module is located in the src/Web_Scraping_Python/Web_Scraping_BeautifullSoap directory\n",
    "import src.Web_Scraping_Python.Web_Scraping_Selenium as selenium\n",
    "\n",
    "# Creating an instance of the IPLPointsTableScraper class\n",
    "# This class is specifically designed to scrape data from the IPL 2023 points table webpage.\n",
    "# It contains methods to handle the web scraping process using Selenium and BeautifulSoup.\n",
    "scraper = selenium.IPLPointsTableScraper()\n",
    "\n",
    "# Fetching and parsing the data from the IPL points table webpage into a pandas DataFrame.\n",
    "# The get_data method of the scraper instance orchestrates the whole process:\n",
    "# It calls the fetch_data method to retrieve the HTML content of the webpage using Selenium,\n",
    "# and then calls the parse_html method to extract and structure the data from the HTML.\n",
    "df = scraper.get_data()\n",
    "\n",
    "# Printing the DataFrame to the console.\n",
    "# This DataFrame contains the structured data from the IPL points table,\n",
    "# including team rankings, points, matches played, wins, losses, etc., depending on the table's columns.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38bdcd",
   "metadata": {},
   "source": [
    "The code defines a class named `IPLPointsTableScraper` for scraping data from the IPL (Indian Premier League) 2023 points table webpage. The class uses Selenium for fetching the web page content and BeautifulSoup for parsing the HTML. It then structures the data into a pandas DataFrame. The usage example demonstrates how to instantiate this class and extract the IPL points table data.\n",
    "\n",
    "### Description of the Dataset:\n",
    "\n",
    "The dataset obtained from this code, stored in `df`, is a pandas DataFrame containing information from the IPL 2023 points table. The specific details depend on the structure of the points table on the webpage, but typically, this dataset can include:\n",
    "\n",
    "- **Team Names**: The names of the cricket teams participating in IPL 2023.\n",
    "- **Matches Played (MP)**: The number of matches played by each team.\n",
    "- **Wins**: The number of matches won by each team.\n",
    "- **Losses**: The number of matches lost by each team.\n",
    "- **Ties**: The number of matches that ended in a tie.\n",
    "- **Points**: The total points accumulated by each team (usually based on wins and ties).\n",
    "- **Net Run Rate (NRR)**: A calculation used in cricket to break ties between teams that have the same number of points.\n",
    "\n",
    "\n",
    "### Potential Uses of the Dataset:\n",
    "\n",
    "1. **Sports Analytics**: Analyze team performances, standings, and trends throughout the IPL season.\n",
    "2. **Data Visualization**: Create charts and graphs to visually represent team standings, win/loss ratios, and other statistics.\n",
    "3. **Fantasy Cricket**: Aid in decision-making for fantasy cricket leagues by providing up-to-date team performance data.\n",
    "4. **Predictive Modeling**: Use historical data from the points table for predictive analyses, like forecasting potential playoff contenders or match outcomes.\n",
    "5. **Fan Engagement**: Use in applications or websites dedicated to IPL fans for providing the latest standings and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some EDA on ipl data set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
